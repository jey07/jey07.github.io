---
title: Acceptance-rejection algorithm
author: Naveen Gabriel
date: '2020-12-18'
slug: []
categories: []
tags: []
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>A probability distribution gives the probability of having Y. To get Y or random value from probability, a usual method is to find inverse CDF. There are several pdf whose inverse have no closed solution or difficult to obtain. Acceptance/Rejection method is used when it is not possible to find inverse CDF of a distribution so that we can get random variable (rv) using inverse but we have a pdf for the distribution.</p>
<p>
<p>You might be thinking why we need sampling method, that too generating random samples from probability. Imagine you have dataset where there are missing values and you might know a distribution from which the samples can be generated. But taking the inverse of that distribution might be too difficult. In that case we can use this method. It might feel weird to do this process because we dont encounter it while doing sampling. Many known densities (exponential, normal, beta etc) have library methods tha generate samples using one of different sampling method. Unlike inverse CDF, this method can be extend to multivariate random variables.</p>
<p>In acceptance rejection method, the idea is to find a probabiliy distribution, <span class="math inline">\(g_y\)</span>, from which we can generate a random variable (rv) Y and able to tell whether this rv can be accepted for our target distribution, <span class="math inline">\(f_y\)</span>. The random variable Y is chosen in such a way that the <span class="math inline">\(g_y\)</span> can be scaled to majorize <span class="math inline">\(f_y\)</span> using some constant c; that is <span class="math inline">\(c.g_y(x)\geq f_y(x)\)</span>. The density <span class="math inline">\(g_y\)</span> is known as majorizing density or proposal density and <span class="math inline">\(f_y\)</span> is known as target density. The <a href="https://math.stackexchange.com/questions/2667060/support-of-density-function">support</a> of the target density must be contained in the support of proposal density. For density having infinite support, the majorizing density should also have infinite support. In the case of infinite support, it is critical that the majorizing density should not approach zero faster than the target density</p>
<ul>
<li><strong>Following is the Acceptance Rejection algorithm :</strong></li>
</ul>
<ol style="list-style-type: decimal">
<li>Sample <span class="math display">\[Y \sim g_y(x)\]</span>.</li>
<li>Sample <span class="math display">\[U \sim Unif(0,1)\]</span>.</li>
<li>Reject Y if U &gt; <span class="math display">\[\frac{f_y(x)}{C.g_y(x)}\]</span>. Go to step 1.</li>
<li>Else accept Y for <span class="math display">\[f_y(x)\]</span>.</li>
<li>Keep repeating the above step for desired number of samples.</li>
</ol>
<p>
Step 2 generates uniform probability between 0 and 1. I did not find much meaning of the ratio but I assume that the ratio <span class="math inline">\(f_y(x)/g_y(x)\)</span> is bounded by a constant c.Â c.g(x) acts as a envelope for the target function <span class="math inline">\(f_y\)</span>. One way to think about this fraction is that, it inherently implies that how many fraction of rv for <span class="math inline">\(f_y\)</span> is included in c*<span class="math inline">\(g_y\)</span>. Step 3 implies that if the probability of generated point is lesser than probability generated by uniform distribution then reject that sample, which I find is a nice way to think about it. We need to maximize this fraction so that we can cover most of the points in <span class="math inline">\(g_y\)</span> for <span class="math inline">\(f_y\)</span>. For this we need to take differential and equate it to zero.
</p>
<p>{: .text-justify}</p>
<p>As an example, lets generate samples for normal distribution -<span class="math display">\[\mathcal{N(0,1)}\]</span> using laplace or double exponential distribution as proposal density DE(0, 1).</p>
<p><span class="math display">\[
\begin{aligned}
    g(x|\mu=0,\alpha=1) &amp;= \frac{1}{2}* e^{-|x|} - Laplace Distribution  \\
    f(x |\mu=0,\alpha=1) &amp;=  \frac{1}{\sqrt{2\pi}}* e^{\frac{-x^{2}}{2}} - Normal Distribution \\
\end{aligned}
\]</span></p>
<p><span class="math display">\[\begin{aligned}
    C&amp;\geq \frac{f(x)}{g(x)} \\
    C&amp;\geq \frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}}
\end{aligned}
\]</span></p>
<p>
Then we differentiate the above ratio and equate to 0 to get the value of x which will give the value of C.
</p>
<p>{: .text-justify}</p>
<p><span class="math display">\[\frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}} *(\frac{|x|}{x}-x) \]</span></p>
<p>
Setting the above differential to zero we get the maximum value of above equation at x=1, value of C is obtained.
</p>
<p>{: .text-justify}</p>
<p><span class="math display">\[ C = \sqrt{\frac{2e}{\pi}} \]</span></p>
<p>The condition to accept RV generated from g(x) as RV for f(x) is :
<span class="math display">\[
\begin{aligned}
U &amp; \leq \frac{f(x)}{C*g(x)} \\
U &amp;\leq 0.5*e^{\frac{x^2}{2} + |x|}
\end{aligned}
\]</span></p>
<pre class="r"><code>accept_reject &lt;- function(sam) {
    f_x &lt;- c()
    cnt &lt;- 1
    while(cnt&lt;=sam){ 
        U &lt;- runif(1,0,1) 
        r_x &lt;- ifelse(U&lt;0.5, log(2*U), -log(2-(2*U)))  #generate a random variable from laplace distribution
        uni &lt;- runif(1)
        frac &lt;- exp(-(r_x^2)/2 + abs(r_x) - 0.5)  #value of f(X)/c(g(X))
    
        if(uni&lt;=frac){
            f_x[cnt]&lt;- r_x
            cnt &lt;- cnt+1
        }
        total &lt;&lt;- total + 1
    }
    
return(f_x)
}

n = 2000
total &lt;-0
values &lt;- accept_reject(n)
normal_dist &lt;- rnorm(2000,0,1)

compare_data &lt;- cbind(values,normal_dist)
compare_data &lt;- as.data.frame(compare_data)

colnames(compare_data) &lt;- c(&quot;Accept_Rejection&quot;,&quot;By_Rnorm&quot;)</code></pre>
<p><img src="jey07.github.io/post/2020-12-18-acceptance-rejection-algorithm/index.en_files/figure-html/hist-normal-1.png" width="672" /></p>
<p>We can see that the normal distribution generated by acceptance rejection method is nearly same as distribution generated by rnorm.</p>
<pre class="r"><code>ggplot(compare_data) + geom_histogram(aes(Accept_Rejection,fill=&quot;Accept_Rejection&quot;),alpha=0.4) + 
       geom_histogram(aes(By_Rnorm,fill =&quot;By_Rnorm&quot;), alpha =0.5)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="jey07.github.io/post/2020-12-18-acceptance-rejection-algorithm/index.en_files/figure-html/hist-normal-exponential-1.png" width="672" /></p>
<p>The expected rejection rate is equal to:
<span class="math display">\[1 - \frac{1}{c} = 0.2398264\]</span></p>
<p><br>
The average rejection rate is :
<span class="math display">\[1 - \frac{2000}{total}\]</span>
<br></p>
<p>Where total is the total number of iterations required to generate 2000 samples. Our average rejection rate is nearly equal to expected rejection rate.</p>
<pre class="r"><code>rj_rt &lt;- 1-(2000/total)
cat(&quot;The average rejection rate is :&quot;, rj_rt)</code></pre>
<pre><code>## The average rejection rate is : 0.2375143</code></pre>
<p>If the random variable is of a reasonably low dimension (less than 10?), then rejection sampling is a plausible general approach. Below are some of the awesome link to understand more of this method:</p>
<ul>
<li><a href="http://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-ARM.pdf">Columbia university notes</a></li>
<li><a href="https://stats.stackexchange.com/questions/391598/understanding-rejection-sampling">Stack overflow</a></li>
<li>Rejection sampling (RS) technique, suggested first by</a href="https://dornsifecms.usc.edu/assets/sites/520/docs/VonNeumann-ams12p36-38.pdf"> John von Neumann</a> in 1951</li>
</ul>
