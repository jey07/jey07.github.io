---
title: Acceptance-rejection algorithm
author: Naveen Gabriel
date: '2020-12-18'
slug: []
categories: []
tags: []
---

A probability distribution gives the probability of having Y. To get Y or random value from probability, a usual method is to find inverse CDF. There are several pdf whose inverse have no closed solution or difficult to obtain.  Acceptance/Rejection method is used when it is not possible to find inverse CDF of a distribution so that we can get random variable (rv) using inverse but we have a pdf for the distribution.

<p>You might be thinking why we need sampling method, that too generating random samples from probability. Imagine you have dataset where there are missing values and you might know a distribution from which the samples can be generated. But taking the inverse of that distribution might be too difficult. In that case we can use this method. It might feel weird to do this process because we dont encounter it while doing sampling. Many known densities (exponential, normal, beta etc) have library methods tha generate samples using one of different sampling method.  Unlike inverse CDF, this method can be extend to multivariate random variables.

In acceptance rejection method, the idea is to find a probabiliy distribution, \(g_y\), from which we can generate a random variable (rv) Y and able to tell whether this rv can be accepted for our target distribution, \(f_y\). The random variable Y is chosen in such a way that the \(g_y\) can be scaled to majorize \(f_y\)  using some constant c; that is \(c.g_y(x)\geq f_y(x)\). The density \(g_y\) is known as majorizing density or proposal density and \(f_y\) is known as target density. The <a href="https://math.stackexchange.com/questions/2667060/support-of-density-function">support</a> of the target density must be contained in the support of proposal density. For density having infinite support, the majorizing density  should also have infinite support. In the case of infinite support, it is critical that the majorizing density should not approach zero faster than the target density. It makes sense now as if there’s a region of the support of f that g can never touch, then that area will never get sampled. 

* **Following is the Acceptance Rejection algorithm :**

1. Sample a rv Y  \(\sim g_y(x)\) ( by taking inverse CDF. Remember, taking inverse of majorizing function should be easy)
2. Sample from uniform distribution U \(\sim\) Unif(0,1).
3. Reject Y if U > \(\frac{f_y(x)}{C.g_y(x)}\). Go to step 1.
4. Else accept Y for \(f_y(x)\). 
5. Keep repeating the above step for desired number of samples.

Step 2 generates uniform probability between 0 and 1. I did not find much meaning of the ratio in Step 3 but I assume that the ratio \(f_y(x)/g_y(x)\) is bounded by a constant c>0. c.g(x) acts as a envelope for the target function \(f_y\). One way to think about this fraction is that, it inherently implies that how many fraction of rv for \(f_y\) is included in c*\(g_y\). Step 3 implies that if the probability of generated point is lesser than probability generated by uniform distribution then accept that sample, which I find is a nice way to think about it. We need to maximize this fraction so that we can cover most of the points in \(g_y\) for \(f_y\).

As an example, lets generate samples for normal distribution \(\mathcal{N(0,1)}\) using laplace or double exponential distribution as proposal density DE(0, 1). Below are the given two distribution :

```{r include=FALSE}
library(ggplot2)
```

$$
\begin{aligned}
    g(x|\mu=0,\alpha=1) &= \frac{1}{2}* e^{-|x|}  \hspace{40pt} :Laplace Distribution  \\
    f(x |\mu=0,\alpha=1) &=  \frac{1}{\sqrt{2\pi}}* e^{\frac{-x^{2}}{2}} \hspace{24pt} :Normal Distribution \\
\end{aligned}
$$

As I mentioned about that the ratio \(f_y(x)/g_y(x)\) is bounded by a constant c>0 and \(sup_x{f(x)/g(x))}\) \(\le\) c. Another way to imagine the above equation is that, this equation gives the probability of accepting the sample and we need to maximize the sample. So,

$$\begin{aligned}
    C&\geq \frac{f(x)}{g(x)} \\
    C&\geq \frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}}
\end{aligned}
$$

Then we differentiate the above ratio and equate to 0 to get the value of x which will give the value of C. On doing it, we get it as:

$$\frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}} *(\frac{|x|}{x}-x) $$

Setting the above differential to zero we get the maximum value of above equation at x=1, value of C is obtained.

$$ C = \sqrt{\frac{2e}{\pi}} $$


The condition to accept RV generated from g(x) as RV for f(x) is  :
$$
\begin{aligned}
U & \leq \frac{f(x)}{C*g(x)} \\
U &\leq 0.5*e^{\frac{x^2}{2} + |x|}
\end{aligned}
$$

Step 1 of equation is generating samples from laplace distribution whose inverse can be found. This <a href="https://math.stackexchange.com/questions/2667060/support-of-density-function">link</a> gives how to find  he inverse.

Below is the complete code fo acceptance-rejection:

```{r}
accept_reject <- function(sam) {
    f_x <- c()
    cnt <- 1
    while(cnt<=sam){ 
        U <- runif(1,0,1)    
        r_x <- ifelse(U<0.5, log(2*U), -log(2-(2*U)))  #generate a random variable from laplace distribution
        
        uni <- runif(1)
        frac <- exp(-(r_x^2)/2 + abs(r_x) - 0.5)  #value of f(X)/c(g(X))
    
        if(uni<=frac){
            f_x[cnt]<- r_x
            cnt <- cnt+1
        }
        total <<- total + 1
    }
    
return(f_x)
}

n = 2000
total <-0
values <- accept_reject(n)
normal_dist <- rnorm(2000,0,1)

compare_data <- cbind(values,normal_dist)
compare_data <- as.data.frame(compare_data)

colnames(compare_data) <- c("Accept_Rejection","normal_dist")
```


We can see that the normal distribution generated by acceptance rejection method is nearly same as distribution generated by rnorm.
```{r hist-normal-exponential, fig.height=6, fig.width=10, message=FALSE, warning=FALSE}
ggplot(compare_data) + geom_histogram(aes(Accept_Rejection,fill="Accept_Rejection"),alpha=0.4) + 
       geom_histogram(aes(normal_dist,fill ="normal_dist"), alpha =0.5)
```


The expected rejection rate is equal to: 
$$1 - \frac{1}{c} = 0.2398264$$


<br>
The average rejection rate is :
$$1 - \frac{2000}{total}$$ 
<br>

Where total is the total number of iterations required to generate 2000 samples. Our average rejection rate is nearly equal to expected rejection rate.

```{r echo=TRUE}
rj_rt <- 1-(2000/total)
cat("The average rejection rate is :", rj_rt)
```
If the random variable is of a reasonably low dimension (less than  10?), then rejection sampling is a plausible general approach. There are different flavours of rejection sampling like Squeezed rejection sampling, adaptive rejection sampling etc. The acceptance-rejection method can be generalized to the Metropolis–Hastings algorithm which is a type of Markov chain Monte Carlo simulation. Below are some of the awesome link to understand more of this method:

- <a href="http://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-ARM.pdf">Columbia university notes</a>
- <a href="https://stats.stackexchange.com/questions/391598/understanding-rejection-sampling">Stack overflow</a>
- Rejection sampling (RS) technique, suggested first by</a href="https://dornsifecms.usc.edu/assets/sites/520/docs/VonNeumann-ams12p36-38.pdf"> John von Neumann</a> in 1951

