---
title: Acceptance-rejection algorithm
author: Naveen Gabriel
date: '2020-12-18'
slug: []
categories: []
tags: []
---

A probability distribution gives the probability of having Y. To get Y or random value from probability, a usual method is to find inverse CDF. There are several pdf whose inverse have no closed solution or difficult to obtain.  Acceptance/Rejection method is used when it is not possible to find inverse CDF of a distribution so that we can get random variable (rv) using inverse but we have a pdf for the distribution.

<p>You might be thinking why we need sampling method, that too generating random samples from probability. Imagine you have dataset where there are missing values and you might know a distribution from which the samples can be generated. But taking the inverse of that distribution might be too difficult. In that case we can use this method. It might feel weird to do this process because we dont encounter it while doing sampling. Many known densities (exponential, normal, beta etc) have library methods tha generate samples using one of different sampling method.  Unlike inverse CDF, this method can be extend to multivariate random variables.

In acceptance rejection method, the idea is to find a probabiliy distribution, \(g_y\), from which we can generate a random variable (rv) Y and able to tell whether this rv can be accepted for our target distribution, \(f_y\). The random variable Y is chosen in such a way that the \(g_y\) can be scaled to majorize \(f_y\)  using some constant c; that is \(c.g_y(x)\geq f_y(x)\). The density \(g_y\) is known as majorizing density or proposal density and \(f_y\) is known as target density. The <a href="https://math.stackexchange.com/questions/2667060/support-of-density-function">support</a> of the target density must be contained in the support of proposal density. For density having infinite support, the majorizing density  should also have infinite support. In the case of infinite support, it is critical that the majorizing density should not approach zero faster than the target density 

* **Following is the Acceptance Rejection algorithm :**

1. Sample $$Y \sim g_y(x)$$.
2. Sample $$U \sim Unif(0,1)$$.
3. Reject Y if U > $$\frac{f_y(x)}{C.g_y(x)}$$. Go to step 1.
4. Else accept Y for $$f_y(x)$$. 
5. Keep repeating the above step for desired number of samples.

<p>Step 2 generates uniform probability between 0 and 1. I did not find much meaning of the ratio but I assume that the ratio \(f_y(x)/g_y(x)\) is bounded by a constant c. c.g(x) acts as a envelope for the target function \(f_y\). One way to think about this fraction is that, it inherently implies that how many fraction of rv for \(f_y\) is included in c*\(g_y\). Step 3 implies that if the probability of generated point is lesser than probability generated by uniform distribution then reject that sample, which I find is a nice way to think about it.  We need to maximize this fraction so that we can cover most of the points in \(g_y\) for \(f_y\). For this we need to take differential and equate it to zero. </p> {: .text-justify}

As an example, lets generate samples for normal distribution -$$\mathcal{N(0,1)}$$ using laplace or double exponential distribution as proposal density DE(0, 1).

```{r include=FALSE}
library(ggplot2)
```

$$
\begin{aligned}
    g(x|\mu=0,\alpha=1) &= \frac{1}{2}* e^{-|x|} - Laplace Distribution  \\
    f(x |\mu=0,\alpha=1) &=  \frac{1}{\sqrt{2\pi}}* e^{\frac{-x^{2}}{2}} - Normal Distribution \\
\end{aligned}
$$



$$\begin{aligned}
    C&\geq \frac{f(x)}{g(x)} \\
    C&\geq \frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}}
\end{aligned}
$$

<p>Then we differentiate the above ratio and equate to 0 to get the value of x which will give the value of C.</p> {: .text-justify}

$$\frac{\sqrt{2}* e^{-\frac{x^2}{2}+|x|}}{\sqrt{\pi}} *(\frac{|x|}{x}-x) $$

<p>Setting the above differential to zero we get the maximum value of  above equation at x=1, value of C is obtained.</p> {: .text-justify}

$$ C = \sqrt{\frac{2e}{\pi}} $$


The condition to accept RV generated from g(x) as RV for f(x) is  :
$$
\begin{aligned}
U & \leq \frac{f(x)}{C*g(x)} \\
U &\leq 0.5*e^{\frac{x^2}{2} + |x|}
\end{aligned}
$$



```{r}
accept_reject <- function(sam) {
    f_x <- c()
    cnt <- 1
    while(cnt<=sam){ 
        U <- runif(1,0,1) 
        r_x <- ifelse(U<0.5, log(2*U), -log(2-(2*U)))  #generate a random variable from laplace distribution
        uni <- runif(1)
        frac <- exp(-(r_x^2)/2 + abs(r_x) - 0.5)  #value of f(X)/c(g(X))
    
        if(uni<=frac){
            f_x[cnt]<- r_x
            cnt <- cnt+1
        }
        total <<- total + 1
    }
    
return(f_x)
}

n = 2000
total <-0
values <- accept_reject(n)
normal_dist <- rnorm(2000,0,1)

compare_data <- cbind(values,normal_dist)
compare_data <- as.data.frame(compare_data)

colnames(compare_data) <- c("Accept_Rejection","By_Rnorm")
```

```{r hist-normal, echo=FALSE}
hist(compare_data$Accept_Rejection,main = "Normal distribution generated by Accept/Rejection method", xlab = "Random Variables") 
```

We can see that the normal distribution generated by acceptance rejection method is nearly same as distribution generated by rnorm.

```{r hist-normal-exponential}
ggplot(compare_data) + geom_histogram(aes(Accept_Rejection,fill="Accept_Rejection"),alpha=0.4) + 
       geom_histogram(aes(By_Rnorm,fill ="By_Rnorm"), alpha =0.5)
```


The expected rejection rate is equal to: 
$$1 - \frac{1}{c} = 0.2398264$$


<br>
The average rejection rate is :
$$1 - \frac{2000}{total}$$ 
<br>

Where total is the total number of iterations required to generate 2000 samples. Our average rejection rate is nearly equal to expected rejection rate.

```{r echo=TRUE}
rj_rt <- 1-(2000/total)
cat("The average rejection rate is :", rj_rt)
```
If the random variable is of a reasonably low dimension (less than  10?), then rejection sampling is a plausible general approach. Below are some of the awesome link to understand more of this method:

- <a href="http://www.columbia.edu/~ks20/4703-Sigman/4703-07-Notes-ARM.pdf">Columbia university notes</a>
- <a href="https://stats.stackexchange.com/questions/391598/understanding-rejection-sampling">Stack overflow</a>
- Rejection sampling (RS) technique, suggested first by</a href="https://dornsifecms.usc.edu/assets/sites/520/docs/VonNeumann-ams12p36-38.pdf"> John von Neumann</a> in 1951

